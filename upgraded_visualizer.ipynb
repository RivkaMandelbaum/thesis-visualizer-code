{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('anaconda3': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "c14130da412dc9843fd0d7dc2551c3f1f991215061e2f34f7777ed189f09bc2b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "from matplotlib import colors\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../serial-reproduction-with-selection/analysis/data/rivka-necklace-rep-data/psynet/data/\"\n",
    "nodes = pd.read_csv(PATH + \"node.csv\", low_memory=False)\n",
    "networks = pd.read_csv(PATH + \"network.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter networks\n",
    "network_data = networks\n",
    "network_data = network_data[network_data[\"role\"] == \"experiment\"]\n",
    "network_data = network_data[network_data[\"failed\"] == 'f']\n",
    "network_data = network_data[network_data[\"trial_maker_id\"] == 'graph_experiment']\n",
    "\n",
    "experiment_net_id = list(network_data['id'].to_numpy())\n",
    "\n",
    "# filter nodes\n",
    "node_data = nodes\n",
    "node_data = node_data[nodes[\"type\"] == \"graph_chain_node\"]\n",
    "node_data = node_data[node_data[\"failed\"] == \"f\"]\n",
    "node_data = node_data[node_data[\"network_id\"].isin(experiment_net_id)]\n",
    "node_data = node_data[[\"id\", \"network_id\", \"degree\", \"definition\", \"seed\", \"vertex_id\", \"dependent_vertex_ids\"]]\n",
    "node_data = node_data.sort_values([\"network_id\", \"degree\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# slice_graphs = []\n",
    "# min_deg = int(node_data[\"degree\"].min())\n",
    "# max_deg = int(node_data[\"degree\"].max())\n",
    "\n",
    "# for deg in range(min_deg, max_deg + 1):\n",
    "#     print(deg)\n",
    "\n",
    "# ---- TODO: Generalize to each degree ---\n",
    "# add nodes to new Graph\n",
    "deg = node_data[node_data[\"degree\"] == 1.0]\n",
    "G = nx.Graph()\n",
    "for node_id in deg[\"id\"].values.tolist():\n",
    "    v_id = deg[deg[\"id\"] == node_id][\"vertex_id\"].values[0]\n",
    "    G.add_node(node_id, vertex_id=v_id)\n",
    "\n",
    "edges = {}\n",
    "# add edges to the Graph \n",
    "for i, ser in deg.iterrows():\n",
    "    node_id = ser[\"id\"]\n",
    "\n",
    "    # get dependent nodes \n",
    "    dependent_vertices = ser[\"dependent_vertex_ids\"].strip('][').split(',')\n",
    "    dependent_nodes = [deg[deg[\"vertex_id\"] == float(v)] for v in dependent_vertices]\n",
    "    dependent_nodes = [n[\"id\"].values[0] for n in dependent_nodes]\n",
    "\n",
    "    # add as edges\n",
    "    edge_list = [(int(dependent_node), int(node_id)) for dependent_node in dependent_nodes]\n",
    "    G.add_edges_from(edge_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read infos, filter like nodes\n",
    "infos = pd.read_csv(PATH + \"info.csv\")\n",
    "info_data = infos\n",
    "info_data = info_data[infos[\"type\"] == \"graph_chain_trial\"]\n",
    "info_data = info_data[info_data[\"failed\"] == \"f\"]\n",
    "info_data = info_data[[\"id\", \"creation_time\", \"details\", \"origin_id\", \"network_id\", \"participant_id\"]] # TODO: Probably want more columns here \n",
    "\n",
    "info_data = info_data.sort_values([\"network_id\", \"origin_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metadata from infos to each node\n",
    "for n in G.nodes.items():\n",
    "    n_id = n[0]\n",
    "    row = info_data[info_data[\"origin_id\"] == n_id]\n",
    "    G.nodes[n_id]['creation_time'] = row[\"creation_time\"].values[0]\n",
    "    # TODO: Add other infos here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Local cdn resources have problems on chrome/safari when used in jupyter-notebook. \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc8e886dee0>"
      ],
      "text/html": "\n        <iframe\n            width=\"500px\"\n            height=\"500px\"\n            src=\"slice.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        "
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "# convert to PyVis and show\n",
    "pyvis_net = Network('500px', '500px',notebook=True)\n",
    "pyvis_net.from_nx(G)\n",
    "\n",
    "# add labels\n",
    "for n in pyvis_net.nodes:\n",
    "   n['label'] = str(int(n['vertex_id'])) # gets changed to a float if you try to convert it in networkx for some rea\n",
    "\n",
    "pyvis_net.show('slice.html')"
   ]
  }
 ]
}